{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "# change working directory to make src visible\n",
    "os.chdir(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 13\n"
     ]
    },
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.visualization import draw_event\n",
    "from src.dataset import SPDEventsDataset\n",
    "from src.data_generation import SPDEventGenerator\n",
    "from src.normalization import ConstraintsNormalizer, TrackParamsNormalizer\n",
    "from src.dataset import collate_fn_for_set_loss\n",
    "from src.model import TRT\n",
    "\n",
    "seed_everything(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare single batch for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EVENT_TRACKS = 5\n",
    "TRUNCATION_LENGTH = 1024\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import collate_fn_with_class_loss\n",
    "\n",
    "hits_norm = ConstraintsNormalizer()\n",
    "params_norm = TrackParamsNormalizer()\n",
    "train_data = SPDEventsDataset(\n",
    "    max_event_tracks=MAX_EVENT_TRACKS,\n",
    "    generate_fixed_tracks_num=False,\n",
    "    hits_normalizer=hits_norm,\n",
    "    track_params_normalizer=params_norm,\n",
    "    shuffle=True,\n",
    "    truncation_length=TRUNCATION_LENGTH\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn_with_class_loss,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4933, 0.5023, 0.4920, 0.2977, 0.3779, 0.6977, 1.0000],\n",
      "        [0.4933, 0.5023, 0.4920, 0.7344, 0.6183, 0.6966, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "tensor([0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# read single batch for test\n",
    "for batch in train_loader:\n",
    "    print(batch[\"targets\"][0])\n",
    "    print(batch[\"labels\"][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for hungarian loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "def match_targets(outputs, targets):\n",
    "    cost_matrix = torch.cdist(outputs, targets, p=1)\n",
    "    row_ind, col_ind = linear_sum_assignment(\n",
    "        cost_matrix.cpu().detach().numpy()\n",
    "    )\n",
    "    return row_ind, col_ind\n",
    "\n",
    "\n",
    "def hungarian_loss(outputs, targets):\n",
    "    row_ind, col_ind = match_targets(outputs, targets)\n",
    "    matched_outputs = outputs[row_ind]\n",
    "    matched_targets = targets[col_ind]\n",
    "    loss_dist = F.l1_loss(matched_outputs, matched_targets)\n",
    "    return loss_dist\n",
    "\n",
    "\n",
    "def criterion(preds, targets, preds_lengths, targets_lengths):\n",
    "    hungarian = torch.tensor(0.0)\n",
    "    for i in range(preds.shape[0]):\n",
    "        hungarian += hungarian_loss(\n",
    "            preds[i, :preds_lengths[i]],\n",
    "            targets[i, :targets_lengths[i]]\n",
    "        )\n",
    "    hungarian /= preds.shape[0]  # batchmean\n",
    "    return hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['inputs', 'mask', 'targets', 'orig_params', 'n_tracks_per_sample', 'labels'])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 5, 7])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"targets\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test same inputs, but shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Targets:\n",
      "tensor([1, 2, 1, 1, 0, 1, 1, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "def adjust_targets(row_ind, col_ind, targets, num_candidates=10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: Predicted logits with shape [num_candidates, num_classes]\n",
    "        row_ind: Matched row indices for predictions N (for N matched pairs).\n",
    "        col_ind: Matched column indices for predictions N.\n",
    "        targets: Ground truth labels corresponding to matched pairs N.\n",
    "        num_candidates (int): Number of candidates predicted per sample (default=10).\n",
    "\n",
    "    Returns:\n",
    "        adjusted_logits: Logits with shape [num_candidates, num_classes], adjusted for unmatched candidates.\n",
    "        adjusted_targets: Target labels with shape num_candidates, where unmatched candidates get label 1.\n",
    "    \"\"\"\n",
    "    # Initialize adjusted logits and targets\n",
    "    #adjusted_logits = logits  #.clone()  # Copy logits\n",
    "    adjusted_targets = torch.ones(num_candidates, dtype=torch.long)  # Default label is 1 for unmatched candidates\n",
    "\n",
    "    # For each matched pair, assign the corresponding target\n",
    "    matched_rows = row_ind\n",
    "    matched_cols = col_ind\n",
    "    adjusted_targets[matched_rows] = targets[matched_cols]\n",
    "\n",
    "    return adjusted_targets\n",
    "\n",
    "\n",
    "# Test\n",
    "num_candidates = 10\n",
    "num_classes = 5\n",
    "num_matched_pairs = 3\n",
    "\n",
    "# Logits: shape [10, C]\n",
    "logits = torch.randn(num_candidates, num_classes)\n",
    "\n",
    "# Random indices of matched pairs (row_ind and col_ind) for 3 matched elements per sample\n",
    "row_ind =  torch.tensor([1, 4, 7])\n",
    "col_ind = torch.tensor([0, 1, 2])\n",
    "\n",
    "# Targets for matched pairs, shape N\n",
    "targets =  torch.tensor([2, 0, 3])\n",
    "\n",
    "# Adjust logits and targets for unmatched predictions\n",
    "adjusted_targets = adjust_targets(row_ind, col_ind, targets, num_candidates)\n",
    "\n",
    "print(\"Adjusted Targets:\")\n",
    "print(adjusted_targets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare loss and overfit on a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def focal_loss(logits, targets, alpha=1, gamma=2, reduction='mean'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: Predictions for each class with shape [B, N, C] where C is the number of classes (raw logits, not softmaxed).\n",
    "        targets: Ground truth labels with shape [B, N] where each value is in the range [0, C-1].\n",
    "        alpha (float, optional): A balancing factor for classes (default=1).\n",
    "        gamma (float, optional): Focusing parameter for hard examples (default=2).\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "                                      'none' | 'mean' | 'sum'. 'mean': the sum of the output will be divided by the number of elements in the output;\n",
    "                                      'sum': the output will be summed;\n",
    "                                      'none': no reduction will be applied (default='mean').\n",
    "    Returns:\n",
    "        Loss: Scalar if reduction is applied or the same shape as input without reduction.\n",
    "    \"\"\"\n",
    "    # Convert logits to probabilities with softmax\n",
    "    probs = F.softmax(logits, dim=-1)  # [N, C]\n",
    "\n",
    "    # Get the probabilities of the targets\n",
    "    targets = targets.unsqueeze(-1)  # [N, 1] to align with logits\n",
    "    probs_target_class = probs.gather(dim=-1, index=targets).squeeze(-1)  # [N]\n",
    "\n",
    "    # Compute the focal loss\n",
    "    log_pt = torch.log(probs_target_class + 1e-9)  # Stability for log\n",
    "    loss = -alpha * (1 - probs_target_class) ** gamma * log_pt  # Focal loss equation\n",
    "\n",
    "    # Apply the reduction\n",
    "    if reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    else:\n",
    "        return loss  # No reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def match_targets(outputs, targets):\n",
    "    cost_matrix = torch.cdist(outputs, targets, p=1)\n",
    "    row_ind, col_ind = linear_sum_assignment(\n",
    "        cost_matrix.cpu().detach().numpy()\n",
    "    )\n",
    "    return row_ind, col_ind\n",
    "\n",
    "def hungarian_loss(outputs, targets, distance: Callable):\n",
    "\n",
    "    # loss = F.l1_loss(matched_outputs, matched_targets)\n",
    "    # loss = F.smooth_l1_loss(matched_outputs, matched_targets)\n",
    "    # loss = F.mse_loss(matched_outputs, matched_targets)\n",
    "    loss = distance(outputs, targets)\n",
    "    return loss\n",
    "\n",
    "def class_loss(outputs, targets, loss_fn: Callable):\n",
    "    return loss_fn(outputs, targets)\n",
    "\n",
    "\n",
    "class TRTHungarianLoss(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            distance: Callable = F.l1_loss,\n",
    "            class_loss: Callable = F.cross_entropy,\n",
    "            weights: tuple[float, float] = (1, 1)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._distance = distance\n",
    "        self._class_loss = class_loss\n",
    "        self._weights = weights\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            preds: dict[str, torch.Tensor],\n",
    "            targets: dict[str, torch.Tensor],\n",
    "            preds_lengths,\n",
    "            targets_lengths,\n",
    "    ):\n",
    "        batch_size = preds[\"params\"].shape[0]\n",
    "        pred_logits = preds[\"logits\"]\n",
    "        pred_params = preds[\"params\"]\n",
    "        target_params = targets[\"targets\"]\n",
    "        target_labels = targets[\"labels\"]\n",
    "        hungarian = torch.tensor(0.0).to(pred_params.device)\n",
    "        label_loss = torch.tensor(0.0).to(pred_params.device)\n",
    "        for i in range(batch_size):\n",
    "            row_ind, col_ind = match_targets(\n",
    "                pred_params[i, :preds_lengths[i]],\n",
    "                target_params[i, :targets_lengths[i]])\n",
    "            matched_outputs = pred_params[i, row_ind]\n",
    "            matched_targets = target_params[i, col_ind]\n",
    "            hungarian += hungarian_loss(\n",
    "                matched_outputs,\n",
    "                matched_targets,\n",
    "                distance=self._distance\n",
    "            )\n",
    "            matched_targets = adjust_targets(\n",
    "                row_ind,\n",
    "                col_ind,\n",
    "                target_labels[i, :targets_lengths[i]],\n",
    "                num_candidates=pred_logits.shape[1]\n",
    "            )\n",
    "            label_loss += class_loss(\n",
    "                pred_logits[i],\n",
    "                matched_targets,\n",
    "                loss_fn=self._class_loss\n",
    "            )\n",
    "        print(f\"Params: {hungarian}, class: {label_loss}\")\n",
    "        hungarian /= batch_size  # batchmean\n",
    "        label_loss /= batch_size  # batchmean\n",
    "        return self._weights[0] * hungarian + self._weights[1] * label_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "criterion = TRTHungarianLoss(class_loss=focal_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the loss"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "model = TRT(\n",
    "    num_candidates=30,\n",
    "    n_points=TRUNCATION_LENGTH,\n",
    "    num_out_params=batch[\"targets\"].shape[2]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(batch[\"inputs\"], batch[\"mask\"])\n",
    "\n",
    "print(outputs[\"params\"].shape)\n",
    "print(outputs[\"logits\"].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import src\n",
    "import importlib\n",
    "importlib.reload(src.model_hybrid)\n",
    "from src.model_hybrid import TRTHybrid\n",
    "\n",
    "model_h = TRTHybrid(\n",
    "    num_candidates=30,\n",
    "    n_points=TRUNCATION_LENGTH,\n",
    "    num_out_params=batch[\"targets\"].shape[2],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 30, 7])\n",
      "torch.Size([16, 30, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model_h(inputs=batch[\"inputs\"], mask=batch[\"mask\"])\n",
    "\n",
    "print(outputs[\"params\"].shape)\n",
    "print(outputs[\"logits\"].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([MAX_EVENT_TRACKS]*len(outputs[\"params\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Distance for Hungarian Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83e5435970ca48f8bad248b0e9e5bb63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: 2.812659978866577, class: 9.474464416503906\n",
      "Params: 2.834296703338623, class: 7.853271484375\n",
      "Params: 2.695072650909424, class: 8.25096321105957\n",
      "Params: 2.6097097396850586, class: 7.808986663818359\n",
      "Params: 2.5693938732147217, class: 7.997611045837402\n",
      "Params: 2.587691307067871, class: 7.955904960632324\n",
      "Params: 2.553248167037964, class: 8.128861427307129\n",
      "Params: 2.583043336868286, class: 7.879493713378906\n",
      "Params: 2.5578019618988037, class: 8.06248664855957\n",
      "Params: 2.524580478668213, class: 7.972891330718994\n",
      "Params: 2.5760984420776367, class: 7.640210151672363\n",
      "Params: 2.5480759143829346, class: 7.7768378257751465\n",
      "Params: 2.4809556007385254, class: 7.59494161605835\n",
      "Params: 2.5394206047058105, class: 7.6606340408325195\n",
      "Params: 2.489503860473633, class: 7.477675437927246\n",
      "Params: 2.5255320072174072, class: 7.683346271514893\n",
      "Params: 2.4887702465057373, class: 7.5580525398254395\n",
      "Params: 2.454681158065796, class: 7.181545257568359\n",
      "Params: 2.5092999935150146, class: 7.310067176818848\n",
      "Params: 2.4596831798553467, class: 7.255108833312988\n",
      "Params: 2.495265245437622, class: 7.056575298309326\n",
      "Params: 2.4645204544067383, class: 6.915678024291992\n",
      "Params: 2.449383497238159, class: 6.816908836364746\n",
      "Params: 2.4436657428741455, class: 6.685976982116699\n",
      "Params: 2.4634480476379395, class: 6.3153791427612305\n",
      "Params: 2.483299732208252, class: 5.878841876983643\n",
      "Params: 2.454266309738159, class: 5.98164176940918\n",
      "Params: 2.4035322666168213, class: 5.7411394119262695\n",
      "Params: 2.400618553161621, class: 5.608856678009033\n",
      "Params: 2.3728740215301514, class: 5.244650363922119\n",
      "Params: 2.346590280532837, class: 5.14617395401001\n",
      "Params: 2.333529233932495, class: 5.144582271575928\n",
      "Params: 2.371055841445923, class: 4.2108869552612305\n",
      "Params: 2.3087503910064697, class: 4.150933742523193\n",
      "Params: 2.3538658618927, class: 5.27298641204834\n",
      "Params: 2.355215072631836, class: 4.684101104736328\n",
      "Params: 2.32421612739563, class: 3.497230291366577\n",
      "Params: 2.296495199203491, class: 3.804565668106079\n",
      "Params: 2.313272476196289, class: 3.820950746536255\n",
      "Params: 2.2812249660491943, class: 4.009663105010986\n",
      "Params: 2.2679452896118164, class: 3.713761329650879\n",
      "Params: 2.2512359619140625, class: 4.5440354347229\n",
      "Params: 2.3078019618988037, class: 4.639836311340332\n",
      "Params: 2.237072229385376, class: 4.5246901512146\n",
      "Params: 2.205498218536377, class: 4.034978866577148\n",
      "Params: 2.275742769241333, class: 4.6910905838012695\n",
      "Params: 2.2143843173980713, class: 4.859299659729004\n",
      "Params: 2.2561166286468506, class: 3.5377237796783447\n",
      "Params: 2.229116678237915, class: 3.630910634994507\n",
      "Params: 2.1808969974517822, class: 3.7148613929748535\n",
      "Params: 2.1962950229644775, class: 4.087530136108398\n",
      "Params: 2.136679172515869, class: 3.7630808353424072\n",
      "Params: 2.1493399143218994, class: 4.072856903076172\n",
      "Params: 2.071316719055176, class: 4.261163234710693\n",
      "Params: 2.119133472442627, class: 3.891613006591797\n",
      "Params: 2.233922004699707, class: 3.9556851387023926\n",
      "Params: 2.2126166820526123, class: 4.953960418701172\n",
      "Params: 2.1571059226989746, class: 3.9334375858306885\n",
      "Params: 2.2186906337738037, class: 3.3720898628234863\n",
      "Params: 2.0930304527282715, class: 3.4390017986297607\n",
      "Params: 2.0796988010406494, class: 3.7940189838409424\n",
      "Params: 2.0783309936523438, class: 3.3890318870544434\n",
      "Params: 2.1195530891418457, class: 4.420476913452148\n",
      "Params: 2.0871808528900146, class: 4.053442001342773\n",
      "Params: 2.084887981414795, class: 3.8178701400756836\n",
      "Params: 2.0614607334136963, class: 3.593313455581665\n",
      "Params: 2.127286911010742, class: 4.262458801269531\n",
      "Params: 2.1302175521850586, class: 4.9949870109558105\n",
      "Params: 2.0435471534729004, class: 5.3218793869018555\n",
      "Params: 2.071028232574463, class: 4.13268518447876\n",
      "Params: 2.0493061542510986, class: 3.6735575199127197\n",
      "Params: 2.139500856399536, class: 4.156120777130127\n",
      "Params: 2.046325922012329, class: 5.34706449508667\n",
      "Params: 2.065901041030884, class: 6.016758441925049\n",
      "Params: 2.091562509536743, class: 6.2950310707092285\n",
      "Params: 2.05615496635437, class: 4.263052463531494\n",
      "Params: 1.9964603185653687, class: 3.9878885746002197\n",
      "Params: 2.022193670272827, class: 4.282138824462891\n",
      "Params: 2.0389530658721924, class: 4.259612560272217\n",
      "Params: 2.0235981941223145, class: 4.234068870544434\n",
      "Params: 2.0543882846832275, class: 4.911406517028809\n",
      "Params: 1.9791814088821411, class: 4.9704132080078125\n",
      "Params: 2.040464162826538, class: 4.601744174957275\n",
      "Params: 1.9537392854690552, class: 4.35521936416626\n",
      "Params: 1.9276552200317383, class: 3.665621280670166\n",
      "Params: 1.869654655456543, class: 3.3570823669433594\n",
      "Params: 1.9565376043319702, class: 3.8627195358276367\n",
      "Params: 2.0262482166290283, class: 4.491802215576172\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available(\n",
    ") else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "model = TRTHybrid(\n",
    "    num_candidates=MAX_EVENT_TRACKS*3,\n",
    "    n_points=TRUNCATION_LENGTH,\n",
    "    num_out_params=batch[\"targets\"].shape[2]\n",
    ").to(device)\n",
    "criterion = TRTHungarianLoss(weights=(1, 0.01)).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
    "progress_bar = tqdm(range(1000))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = 0\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    outputs = model(batch[\"inputs\"].to(device), batch[\"mask\"].to(device))\n",
    "    loss = criterion(\n",
    "        preds=outputs,\n",
    "        targets={\n",
    "            \"targets\": batch[\"targets\"].to(device),\n",
    "            \"labels\": batch[\"labels\"].to(device),\n",
    "        },\n",
    "        preds_lengths=torch.LongTensor(\n",
    "            [MAX_EVENT_TRACKS]*len(outputs[\"params\"])\n",
    "        ).to(device),\n",
    "        targets_lengths=batch[\"n_tracks_per_sample\"].to(device)\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    progress_bar.set_postfix({\"epoch\": epoch, \"loss\": loss.detach().item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Smooth Distance for Hungarian Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available(\n",
    ") else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "model = TRT(\n",
    "    num_candidates=MAX_EVENT_TRACKS,\n",
    "    n_points=TRUNCATION_LENGTH,\n",
    "    num_out_params=batch[\"targets\"].shape[2]\n",
    ").to(device)\n",
    "criterion = TRTHungarianLoss(distance=F.smooth_l1_loss).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
    "progress_bar = tqdm(range(10000))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = 0\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    outputs = model(batch[\"inputs\"].to(device), batch[\"mask\"].to(device))\n",
    "    loss = criterion(\n",
    "        preds=outputs[\"params\"],\n",
    "        targets=batch[\"targets\"].to(device),\n",
    "        preds_lengths=torch.LongTensor(\n",
    "            [MAX_EVENT_TRACKS]*len(outputs[\"params\"])\n",
    "        ).to(device),\n",
    "        targets_lengths=batch[\"n_tracks_per_sample\"].to(device)\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    progress_bar.set_postfix({\"epoch\": epoch, \"loss\": loss.detach().item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE distance for Hungarian Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available(\n",
    ") else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "model = TRT(\n",
    "    num_candidates=MAX_EVENT_TRACKS,\n",
    "    n_points=TRUNCATION_LENGTH,\n",
    "    num_out_params=batch[\"targets\"].shape[2]\n",
    ").to(device)\n",
    "criterion = TRTHungarianLoss(distance=F.mse_loss).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003)\n",
    "progress_bar = tqdm(range(10000))\n",
    "for epoch in progress_bar:\n",
    "    train_loss = 0\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    outputs = model(batch[\"inputs\"].to(device), batch[\"mask\"].to(device))\n",
    "    loss = criterion(\n",
    "        preds=outputs[\"params\"],\n",
    "        targets=batch[\"targets\"].to(device),\n",
    "        preds_lengths=torch.LongTensor(\n",
    "            [MAX_EVENT_TRACKS]*len(outputs[\"params\"])\n",
    "        ).to(device),\n",
    "        targets_lengths=batch[\"n_tracks_per_sample\"].to(device)\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    progress_bar.set_postfix({\"epoch\": epoch, \"loss\": loss.detach().item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
